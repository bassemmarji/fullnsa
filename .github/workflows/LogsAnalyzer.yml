name: Salesforce Logs Analyzer

on:
  workflow_dispatch:
    inputs:
      org_alias:
        type: string
        description: "Salesforce org alias"
        required: true
        default: "dev"
      days_back:
        type: number
        description: "Number of days back to retrieve logs"
        required: true
        default: 30

    
env:
  ORG_ALIAS: ${{ github.event.inputs.org_alias }}
  DAYS_BACK: ${{ github.event.inputs.days_back }}
  NODE_VERSION: "20"
  LOG_DIR: "sf-logs"

jobs:
  collect-logs:
    name: Setup Environment & Collect Logs
    runs-on: ubuntu-latest
    outputs:
      log_count: ${{ steps.query.outputs.log_count }}
      has_logs: ${{ steps.query.outputs.has_logs }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Latest Salesforce CLI
        run: |
          # Download the official install script
          curl https://raw.githubusercontent.com/salesforcecli/installer/main/scripts/install.sh | bash
          echo "$HOME/.sf/bin" >> $GITHUB_PATH
      
          # Verify installation
          sf version --verbose
    
      - name: Install dependencies
        run: |
          # Install jq for JSON processing
          sudo apt-get update && sudo apt-get install -y jq
      
      - name: ðŸ” Authenticate to Salesforce Org
        run: |
          echo "${{ secrets.ORG_SFDX_URL }}" | sf org login sfdx-url --alias $ORG_ALIAS --set-default --sfdx-url-stdin
          sf org list

      - name: Query Debug Logs
        id: query
        timeout-minutes: 10
        run: |
          # Calculate start time (UTC)
          START_TIME=$(date -u -d "$DAYS_BACK days ago" '+%Y-%m-%dT%H:%M:%S.000Z')
          echo "ðŸ” Querying logs since: $START_TIME"
          
          # Create log directory
          mkdir -p "$LOG_DIR"
          
          # Query logs with proper SOQL syntax
          QUERY="SELECT Id, Application, DurationMilliseconds, LogLength, LogUserId, Operation, StartTime, Status FROM ApexLog WHERE StartTime >= ${START_TIME} ORDER BY StartTime DESC LIMIT 1000"
          
          echo "Executing SOQL query..."
          sf data query \
            --query "$QUERY" \
            --target-org "$ORG_ALIAS" \
            --result-format json > logs_query.json
            
          # Check if query was successful
          if [ $? -ne 0 ]; then
            echo "âŒ Failed to execute SOQL query"
            cat logs_query.json
            exit 1
          fi
          
          # Extract log information
          log_count=$(jq -r '.result.totalSize' logs_query.json)
          
          if [ "$log_count" -eq 0 ]; then
            echo "âš ï¸ No logs found in the last $DAYS_BACK days"
            echo "log_count=0" >> $GITHUB_OUTPUT
            echo "has_logs=false" >> $GITHUB_OUTPUT
            echo "No logs found in the last $DAYS_BACK days" > "$LOG_DIR/no-logs-found.txt"
          else
            echo "ðŸ“Š Found $log_count debug logs"
            echo "log_count=$log_count" >> $GITHUB_OUTPUT
            echo "has_logs=true" >> $GITHUB_OUTPUT
            
            # Save log metadata
            jq '.result.records[] | {Id, Application, DurationMilliseconds, LogLength, Operation, StartTime, Status}' \
              logs_query.json > "$LOG_DIR/log_metadata.json"
          fi

      - name: Download Log Contents
        if: steps.query.outputs.has_logs == 'true'
        timeout-minutes: 45
        run: |
          echo "ðŸ“¥ Downloading log contents..."
          
          # Extract log IDs
          log_ids=$(jq -r '.result.records[].Id' logs_query.json)
          total_logs=$(echo "$log_ids" | wc -l)
          current=0
          
          echo "Starting download of $total_logs logs..."
          
          # Download logs with progress tracking
          for logid in $log_ids; do
            current=$((current + 1))
            echo "[$current/$total_logs] Attempting to download log: $logid"
            
            # Use sf data get record to fetch the Log field (base64-encoded)
            response=$(mktemp)
            if sf data get record \
                --sobject "ApexLog" \
                --sobject-id "$logid" \
                --field-content "Log" \
                --target-org "$ORG_ALIAS" > "$response" 2>&1; then
      
              # Check if response is non-empty and looks like base64
              if [ -s "$response" ] && head -c 100 "$response" | grep -qE '^[a-zA-Z0-9+/]*={0,2}$'; then
                # Decode base64 to .log file
                base64 -d "$response" > "$LOG_DIR/$logid.log"
                echo "âœ… Successfully downloaded and decoded $logid"
                downloaded_count=$((downloaded_count + 1))
              else
                echo "âš ï¸ Log $logid downloaded but content appears invalid"
                echo "$logid (invalid content)" >> "$LOG_DIR/failed_downloads.txt"
                cat "$response" >> "$LOG_DIR/errors_$logid.txt"
              fi
            else
              echo "âŒ Failed to retrieve log record $logid:"
              cat "$response"
              echo "$logid" >> "$LOG_DIR/failed_downloads.txt"
            fi
      
            rm -f "$response"
            sleep 0.5
          done
          
          # Count successful downloads
          downloaded_count=$(find "$LOG_DIR" -name "*.log" | wc -l)
          echo "âœ… Successfully downloaded $downloaded_count out of $total_logs logs"
          
          # Create download summary
          cat > "$LOG_DIR/download_summary.txt" << EOF
          Download Summary
          ================
          Total logs found: $total_logs
          Successfully downloaded: $downloaded_count
          Failed downloads: $([ -f "$LOG_DIR/failed_downloads.txt" ] && wc -l < "$LOG_DIR/failed_downloads.txt" || echo "0")
          Time range: Last $DAYS_BACK days
          Downloaded on: $(date -u)
          EOF

      - name: Upload Log Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: salesforce-debug-logs-${{ env.ORG_ALIAS }}-${{ github.run_number }}
          path: ${{ env.LOG_DIR }}
          retention-days: 7
          if-no-files-found: warn
          


