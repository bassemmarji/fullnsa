name: Salesforce Logs Analyzer

on:
  workflow_dispatch:
    inputs:
      org_alias:
        type: string
        description: "Salesforce org alias"
        required: true
        default: "dev"
      days_back:
        type: number
        description: "Number of days back to retrieve logs"
        required: true
        default: 30

    
env:
  ORG_ALIAS: ${{ github.event.inputs.org_alias }}
  DAYS_BACK: ${{ github.event.inputs.days_back }}
  NODE_VERSION: "20"
  LOG_DIR: "sf-logs"

jobs:
  collect-logs:
    name: Setup Environment & Collect Logs
    runs-on: ubuntu-latest
    outputs:
      log_count: ${{ steps.query.outputs.log_count }}
      has_logs: ${{ steps.query.outputs.has_logs }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install dependencies
        run: |
          # Install Salesforce CLI
          npm install --global @salesforce/cli
          sf plugins:update
          sf --version
          
          # Install jq for JSON processing
          sudo apt-get update && sudo apt-get install -y jq
      
      - name: ðŸ” Authenticate to Salesforce Org
        run: |
          echo "${{ secrets.ORG_SFDX_URL }}" | sf org login sfdx-url --alias $ORG_ALIAS --set-default --sfdx-url-stdin
          sf org list

      - name: Query Debug Logs
        id: query
        timeout-minutes: 10
        run: |
          # Calculate start time (UTC)
          START_TIME=$(date -u -d "$DAYS_BACK days ago" '+%Y-%m-%dT%H:%M:%S.000Z')
          echo "ðŸ” Querying logs since: $START_TIME"
          
          # Create log directory
          mkdir -p "$LOG_DIR"
          
          # Query logs with proper SOQL syntax
          QUERY="SELECT Id, Application, DurationMilliseconds, LogLength, LogUserId, Operation, StartTime, Status FROM ApexLog WHERE StartTime >= ${START_TIME} ORDER BY StartTime DESC LIMIT 1000"
          
          echo "Executing SOQL query..."
          sf data query \
            --query "$QUERY" \
            --target-org "$ORG_ALIAS" \
            --result-format json > logs_query.json
            
          # Check if query was successful
          if [ $? -ne 0 ]; then
            echo "âŒ Failed to execute SOQL query"
            cat logs_query.json
            exit 1
          fi
          
          # Extract log information
          log_count=$(jq -r '.result.totalSize' logs_query.json)
          
          if [ "$log_count" -eq 0 ]; then
            echo "âš ï¸ No logs found in the last $DAYS_BACK days"
            echo "log_count=0" >> $GITHUB_OUTPUT
            echo "has_logs=false" >> $GITHUB_OUTPUT
            echo "No logs found in the last $DAYS_BACK days" > "$LOG_DIR/no-logs-found.txt"
          else
            echo "ðŸ“Š Found $log_count debug logs"
            echo "log_count=$log_count" >> $GITHUB_OUTPUT
            echo "has_logs=true" >> $GITHUB_OUTPUT
            
            # Save log metadata
            jq '.result.records[] | {Id, Application, DurationMilliseconds, LogLength, Operation, StartTime, Status}' \
              logs_query.json > "$LOG_DIR/log_metadata.json"
          fi

      - name: Download Log Contents
        if: steps.query.outputs.has_logs == 'true'
        timeout-minutes: 45
        run: |
          echo "ðŸ“¥ Downloading log contents..."
          
          # Extract log IDs
          log_ids=$(jq -r '.result.records[].Id' logs_query.json)
          total_logs=$(echo "$log_ids" | wc -l)
          current=0
          
          echo "Starting download of $total_logs logs..."
          
          # Download logs with progress tracking
          for logid in $log_ids; do
            current=$((current + 1))
            echo "[$current/$total_logs] Attempting to download log: $logid"
            
            # Use sf apex get log with proper error handling
            if sf apex get log "$logid" --target-org "$ORG_ALIAS" --output-dir "$LOG_DIR"; then
              echo "âœ… Downloaded $logid"
            else
              echo "âš ï¸ Failed to download $logid"
              echo "$logid" >> "$LOG_DIR/failed_downloads.txt"
            fi

            # Add small delay to avoid rate limiting
            sleep 0.5
          done
          
          # Count successful downloads
          downloaded_count=$(find "$LOG_DIR" -name "*.log" | wc -l)
          echo "âœ… Successfully downloaded $downloaded_count out of $total_logs logs"
          
          # Create download summary
          cat > "$LOG_DIR/download_summary.txt" << EOF
          Download Summary
          ================
          Total logs found: $total_logs
          Successfully downloaded: $downloaded_count
          Failed downloads: $([ -f "$LOG_DIR/failed_downloads.txt" ] && wc -l < "$LOG_DIR/failed_downloads.txt" || echo "0")
          Time range: Last $DAYS_BACK days
          Query executed: $(date -u)
          EOF

      - name: Upload Log Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: salesforce-debug-logs-${{ env.ORG_ALIAS }}-${{ github.run_number }}
          path: ${{ env.LOG_DIR }}
          retention-days: 7
          if-no-files-found: warn
          


