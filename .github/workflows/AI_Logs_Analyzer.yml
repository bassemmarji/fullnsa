name: AI-Powered User Activity Analyzer11

on:
  workflow_dispatch:
    inputs:
      org_alias:
        description: "Salesforce org alias"
        required: true
        default: "dev"
      days_back:
        description: "Number of days back to retrieve user activity data"
        required: true
        default: 30
        type: number
      model_name:
        description: "Ollama model to use"
        type: choice
        options:
          - llama3:latest
          - gpt-oss:latest
        default: llama3:latest

env:
  ORG_ALIAS: ${{ inputs.org_alias }}
  DAYS_BACK: ${{ inputs.days_back }}
  MODEL_NAME: ${{ inputs.model_name }}
  NODE_VERSION: "20"
  DATA_DIR: "user-activity-data"

jobs:
  collect-user-data:
    name: Collect User Activity Data
    runs-on: ubuntu-latest
    outputs:
      login_count: ${{ steps.query-logins.outputs.login_count }}
      user_count: ${{ steps.query-users.outputs.user_count }}
      has_data: ${{ steps.check-data.outputs.has_data }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup core tools
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          npm install --global @salesforce/cli
          sf plugins:update
          
      - name: üîê Authenticate to Salesforce Org
        run: |
          echo "${{ secrets.ORG_SFDX_URL }}" | sf org login sfdx-url --alias $ORG_ALIAS --set-default --sfdx-url-stdin
          sf org list

      - name: Query Login History
        id: query-logins
        timeout-minutes: 15
        run: |
          START_TIME=$(date -u -d "$DAYS_BACK days ago" '+%Y-%m-%dT%H:%M:%S.000Z')
          echo "üîç Querying login history since: $START_TIME"
          
          mkdir -p "$DATA_DIR"
          
          LOGIN_QUERY=$(cat <<-SOQL
          SELECT Id, UserId, LoginTime, LoginType, SourceIp, LoginUrl, NetworkId,
                 Browser, Platform, Application, Status, LoginGeoId, TlsProtocol,
                 CipherSuite, OptionsIsGet, OptionsIsPost, CountryIso,
                 ApiType, ApiVersion, ClientVersion, ForwardedForIp
          FROM LoginHistory 
          WHERE LoginTime >= $START_TIME 
          ORDER BY LoginTime DESC 
          LIMIT 1000
          SOQL
          )
          
          sf data query --query "$LOGIN_QUERY" --target-org "$ORG_ALIAS" --result-format json > "$DATA_DIR/login_history.json"
            
          login_count=$(jq -r '.result.totalSize' "$DATA_DIR/login_history.json")
          echo "login_count=$login_count" >> $GITHUB_OUTPUT

      - name: Query User Information
        id: query-users
        timeout-minutes: 10
        run: |
          user_ids=$(jq -r '.result.records[].UserId' "$DATA_DIR/login_history.json" | sort -u | head -100)
          user_count=$(echo "$user_ids" | wc -l | awk '{print $1}')
          
          if [ "$user_count" -gt 0 ]; then
            USER_QUERY=$(cat <<-SOQL
            SELECT Id, Username, Name, Email, Profile.Name, UserRole.Name, 
                   IsActive, LastLoginDate, CreatedDate, LastModifiedDate,
                   Department, Division, Title, CompanyName, City, State, Country,
                   TimeZoneSidKey, LocaleSidKey, LanguageLocaleKey, UserType,
                   LastPasswordChangeDate, NumberOfFailedLogins, MobilePhone
            FROM User 
            WHERE Id IN ('$(
              echo "$user_ids" | sed "s/^/'/;s/$/'/" | paste -sd ","
            )')
            SOQL
            )
            
            sf data query --query "$USER_QUERY" --target-org "$ORG_ALIAS" --result-format json > "$DATA_DIR/user_details.json"
          fi
          
          echo "user_count=$user_count" >> $GITHUB_OUTPUT

      - name: Query Security Audit Data
        timeout-minutes: 15
        run: |
          SETUP_START_TIME=$(date -u -d "$DAYS_BACK days ago" '+%Y-%m-%dT%H:%M:%S.000Z')
          
          SETUP_QUERY=$(cat <<-SOQL
          SELECT Id, Action, Section, CreatedDate, CreatedById, CreatedBy.Username,
                 CreatedBy.Name, Display, DelegateUser, ResponsibleNamespacePrefix
          FROM SetupAuditTrail 
          WHERE CreatedDate >= $SETUP_START_TIME 
            AND (Action LIKE '%User%' OR Action LIKE '%Login%' OR Action LIKE '%Password%' 
                 OR Action LIKE '%Profile%' OR Action LIKE '%Permission%' OR Action LIKE '%Security%')
          ORDER BY CreatedDate DESC 
          LIMIT 500
          SOQL
          )
          
          sf data query --query "$SETUP_QUERY" --target-org "$ORG_ALIAS" --result-format json > "$DATA_DIR/setup_audit_trail.json" || true

      - name: Generate Data Summary
        id: check-data
        run: |
          login_count=$(jq -r '.result.totalSize // 0' "$DATA_DIR/login_history.json")
          
          if [ "$login_count" -eq 0 ]; then
            echo "has_data=false" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          jq -n --arg days "$DAYS_BACK" --slurpfile login "$DATA_DIR/login_history.json" \
          '{
            summary: {
              days_analyzed: ($days | tonumber),
              total_logins: $login[0].result.totalSize,
              analysis_period: {
                start: ($login[0].result.records | map(.LoginTime) | min),
                end: ($login[0].result.records | map(.LoginTime) | max)
              },
              unique_users: ($login[0].result.records | map(.UserId) | unique | length),
              unique_ips: ($login[0].result.records | map(.SourceIp) | unique | length),
              login_types: ($login[0].result.records | group_by(.LoginType) | map({type: .[0].LoginType, count: length})),
              platforms: ($login[0].result.records | group_by(.Platform) | map({platform: .[0].Platform, count: length}))
            }
          }' > "$DATA_DIR/data_summary.json"
          
          echo "has_data=true" >> $GITHUB_OUTPUT

      - name: Upload Data Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: user-activity-data
          path: ${{ env.DATA_DIR }}
          retention-days: 3

      - name: Create Summary Report
        run: |
          login_count=${{ steps.query-logins.outputs.login_count }}
          user_count=${{ steps.query-users.outputs.user_count }}
          has_data=${{ steps.check-data.outputs.has_data }}
          
          echo "## üìä Data Collection Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **Org Alias:** $ORG_ALIAS" >> $GITHUB_STEP_SUMMARY
          echo "- **Analysis Period:** $DAYS_BACK days" >> $GITHUB_STEP_SUMMARY
          echo "- **Login Records:** $login_count" >> $GITHUB_STEP_SUMMARY
          echo "- **Users Analyzed:** $user_count" >> $GITHUB_STEP_SUMMARY
          
          if [ "$has_data" = "true" ]; then
            echo "- **Status:** ‚úÖ Data collected successfully" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **Status:** ‚ö†Ô∏è No login data found" >> $GITHUB_STEP_SUMMARY
          fi

  analyze-user-activity:
    name: Analyze User Activity
    runs-on: ubuntu-latest
    needs: collect-user-data
    if: ${{ needs.collect-user-data.outputs.has_data == 'true' }}
    env:
      ANALYSIS_DIR: "analysis-results"
    steps:
      - name: Download Data Artifacts
        uses: actions/download-artifact@v4
        with:
          name: user-activity-data
          path: ${{ env.DATA_DIR }}

      - name: Install Analysis Tools
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          curl -fsSL https://ollama.com/install.sh | sh
          echo "$HOME/.ollama/bin" >> $GITHUB_PATH

      - name: Start Ollama Service
        run: |
          ollama serve > /dev/null 2>&1 &
          echo "OLLAMA_PID=$!" >> $GITHUB_ENV
          sleep 10

      - name: Load AI Model
        timeout-minutes: 30
        run: ollama pull $MODEL_NAME

      - name: Run Security Analysis
        timeout-minutes: 45
        run: |
          mkdir -p $ANALYSIS_DIR
          REPORT_FILE="$ANALYSIS_DIR/user_activity_analysis.md"
          
          # Create analysis prompt
          jq -n \
            --arg model "$MODEL_NAME" \
            --arg days "$DAYS_BACK" \
            --slurpfile login "$DATA_DIR/login_history.json" \
            --slurpfile users "$DATA_DIR/user_details.json" \
            --slurpfile audit "$DATA_DIR/setup_audit_trail.json" \
            --argjson summary "$(cat $DATA_DIR/data_summary.json)" \
          '{
            model: $model,
            period: $days,
            summary: $summary,
            login_history: $login[0],
            user_details: $users[0],
            audit_trail: $audit[0]
          }' > $ANALYSIS_DIR/analysis_input.json
          
          # Generate analysis
          ollama run $MODEL_NAME -f $ANALYSIS_DIR/analysis_prompt.txt < $ANALYSIS_DIR/analysis_input.json > $REPORT_FILE
          
          # Add metadata
          echo -e "\n\n---\n" >> $REPORT_FILE
          echo "**Generated At:** $(date -u)" >> $REPORT_FILE
          echo "**Model Version:** $(ollama show $MODEL_NAME --version)" >> $REPORT_FILE

      - name: Upload Analysis Report
        uses: actions/upload-artifact@v4
        with:
          name: security-analysis-report
          path: ${{ env.ANALYSIS_DIR }}
          retention-days: 14

      - name: Stop Ollama Service
        if: always()
        run: kill $OLLAMA_PID || true

      - name: Create Analysis Summary
        run: |
          echo "## üß† Security Analysis Completed" >> $GITHUB_STEP_SUMMARY
          echo "- **AI Model:** $MODEL_NAME" >> $GITHUB_STEP_SUMMARY
          echo "- **Analysis Period:** $DAYS_BACK days" >> $GITHUB_STEP_SUMMARY
          echo "- **Report Generated:** ‚úÖ [Download artifact](https://github.com/$GITHUB_REPOSITORY/actions/runs/$GITHUB_RUN_ID)" >> $GITHUB_STEP_SUMMARY
