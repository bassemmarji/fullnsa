name: AI-Powered New Data Model Analyzer (Lite-Safe)

on:
  workflow_dispatch:
    inputs:
      org_alias:
        description: "Salesforce org alias"
        required: true
        default: "Full-NSA"
      model_name:
        description: "Ollama model to use"
        required: true
        default: "llama3:latest"

env:
  NODE_VERSION: "20"
  DATA_DIR: "data"  # Simplified for consistency

jobs:
  collect-data:
    name: Collect Salesforce Metadata
    runs-on: ubuntu-latest
    outputs:
      has_data: ${{ steps.check.outputs.has_data }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node + Salesforce CLI
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Salesforce CLI + jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq
          npm install -g @salesforce/cli

      - name: Authenticate to Salesforce
        run: |
          echo "${{ secrets.ORG_SFDX_URL }}" | sf org login sfdx-url \
            --alias "${{ github.event.inputs.org_alias }}" \
            --sfdx-url-stdin

      - name: Test Tooling API Access
        run: |
          echo "üîç Testing post-auth Tooling access..."
          sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
            --query "SELECT count() FROM EntityDefinition LIMIT 1" \
            --result-format human || echo "‚ùå Quick test failed - check permissions"
          echo "üìä Full EntityDefinition count (for reference):"
          sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
            --query "SELECT count() FROM EntityDefinition" \
            --result-format human || echo "‚ùå Full count test failed"

      - name: "üîç Query Salesforce Metadata (Safe Mode - Custom Objects + Relationships)"
        shell: bash
        run: |
          set -e
          echo "üöÄ Starting safe metadata extraction (Custom Objects + Relationships)..."
          mkdir -p "$DATA_DIR"
      
          # === STEP 0: Verify org authentication ===
          echo "üîë Checking Salesforce org authentication..."
          if ! sf org display --target-org "${{ github.event.inputs.org_alias }}" > /dev/null 2>&1; then
            echo "‚ùå Org alias not found or not authenticated: ${{ github.event.inputs.org_alias }}"
            echo "Please ensure the org is authorized using 'sf org login web' or 'sf org login sfdx-url'."
            exit 1
          fi
          echo "‚úÖ Org authentication verified."
      
          # === STEP 1: Fetch Custom Objects Only ===
          echo "üì¶ Querying custom objects..."
          if ! sf data query \
            --use-tooling-api \
            --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT Id, DeveloperName, Label, NamespacePrefix, ExternalSharingModel, InternalSharingModel
                     FROM EntityDefinition
                     WHERE DeveloperName LIKE '%__c'
                     LIMIT 2000" > "$DATA_DIR/objects.json" 2>/tmp/query_objects.log; then
              echo "‚ùå Failed to fetch custom objects. Log:"; cat /tmp/query_objects.log; exit 1
          fi
      
          object_count=$(jq -r '.result.records | length' "$DATA_DIR/objects.json")
          echo "‚úÖ Retrieved $object_count custom objects."
          if [ "$object_count" -eq 0 ]; then
            echo "‚ö†Ô∏è No custom objects found. Exiting safely."
            exit 0
          fi
      
          # === STEP 2: Extract Object API Names ===
          object_names=$(jq -r '.result.records | .[].DeveloperName' "$DATA_DIR/objects.json" | paste -sd, -)
      
          # === STEP 3: Query Field Definitions ===
          echo "üß© Querying field definitions for custom objects..."
          if ! sf data query \
            --use-tooling-api \
            --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT QualifiedApiName, EntityDefinition.DeveloperName, DataType, IsIndexed, IsCalculated, IsNillable, Length, Precision, Scale, ReferenceTo
                     FROM FieldDefinition
                     WHERE EntityDefinition.DeveloperName IN ($object_names)
                     LIMIT 5000" > "$DATA_DIR/fields.json" 2>/tmp/query_fields.log; then
              echo "‚ùå Failed to fetch fields. Log:"; cat /tmp/query_fields.log; exit 1
          fi
      
          field_count=$(jq -r '.result.records | length' "$DATA_DIR/fields.json")
          echo "‚úÖ Retrieved $field_count fields."
      
          # === STEP 4: Extract Relationships (Lookup / Master-Detail) ===
          echo "üîó Extracting relationship fields..."
          jq '.result.records
              | map(select(.DataType == "Lookup" or .DataType == "MasterDetail"))
              | map({field: .QualifiedApiName, parent: .EntityDefinition.DeveloperName, referencedObject: .ReferenceTo})
              ' "$DATA_DIR/fields.json" > "$DATA_DIR/relationships.json"
      
          rel_count=$(jq -r 'length' "$DATA_DIR/relationships.json")
          echo "‚úÖ Extracted $rel_count relationship fields."
      
          # === STEP 5: Query Validation Rules ===
          echo "üß† Querying validation rules..."
          if ! sf data query \
            --use-tooling-api \
            --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT ValidationName, EntityDefinition.DeveloperName, Active, ErrorMessage, Description
                     FROM ValidationRule
                     WHERE Active = true
                     AND EntityDefinition.DeveloperName IN ($object_names)
                     LIMIT 2000" > "$DATA_DIR/validation_rules.json" 2>/tmp/query_vrules.log; then
              echo "‚ùå Failed to fetch validation rules. Log:"; cat /tmp/query_vrules.log; exit 1
          fi
      
          vrule_count=$(jq -r '.result.records | length' "$DATA_DIR/validation_rules.json")
          echo "‚úÖ Retrieved $vrule_count validation rules."
      
          # === STEP 6: Query Apex Triggers ===
          echo "‚öôÔ∏è Querying triggers..."
          if ! sf data query \
            --use-tooling-api \
            --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT Name, TableEnumOrId, Status, CreatedDate, LastModifiedDate
                     FROM ApexTrigger
                     WHERE TableEnumOrId IN ($object_names)
                     LIMIT 2000" > "$DATA_DIR/triggers.json" 2>/tmp/query_triggers.log; then
              echo "‚ùå Failed to fetch triggers. Log:"; cat /tmp/query_triggers.log; exit 1
          fi
      
          trigger_count=$(jq -r '.result.records | length' "$DATA_DIR/triggers.json")
          echo "‚úÖ Retrieved $trigger_count triggers."
      
          echo "üéâ Metadata extraction (custom + relationships) completed successfully."
                    
      - name: Validate Data Availability
        id: check
        run: |
          object_count=$(jq -r '.result.totalSize // .totalSize // 0' "$DATA_DIR/objects.json")
          field_count=$(jq -r '.result.totalSize // .totalSize // 0' "$DATA_DIR/fields.json")
          object_len=$(jq -r '.result.records // .records // [] | length' "$DATA_DIR/objects.json")
          field_len=$(jq -r '.result.records // .records // [] | length' "$DATA_DIR/fields.json")
          echo "Objects: count=$object_count (len=$object_len), Fields: count=$field_count (len=$field_len)"
          if [ "$object_count" -gt 0 ] && [ "$field_count" -gt 0 ]; then
            echo "‚úÖ Data model metadata available"
            echo "has_data=true" >> $GITHUB_OUTPUT
          else
            echo "‚ö†Ô∏è No metadata found (check org/permissions)"
            echo "has_data=false" >> $GITHUB_OUTPUT
          fi

      - uses: actions/upload-artifact@v4
        if: always()  # Upload even on failure for debugging
        with:
          name: data-model-metadata-lite
          path: ${{ env.DATA_DIR }}
          retention-days: 7

  analyze-ai:
    name: Analyze Data Model (AI)
    runs-on: ubuntu-latest
    needs: collect-data
    if: needs.collect-data.outputs.has_data == 'true'
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: data-model-metadata-lite
          path: ${{ env.DATA_DIR }}

      - name: Setup Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve &
          for i in {1..20}; do
            if curl -s http://localhost:11434/api/version >/dev/null; then
              echo "‚úÖ Ollama API ready"
              break
            fi
            echo "‚è≥ Waiting for Ollama to start ($i/20)..."
            sleep 3
          done
          if [ $i -eq 20 ]; then
            echo "‚ùå Ollama failed to start"
            exit 1
          fi
          ollama pull "${{ github.event.inputs.model_name }}"

      - name: Analyze Data Model with AI
        run: |
          echo "üß† Starting AI Analysis Step..."
          REPORT_FILE="data_model_analysis_$(date +%Y%m%d_%H%M%S).md"
          MODEL="${{ github.event.inputs.model_name }}"
      
          echo "üîç Checking metadata files..."
          ls -lh "$DATA_DIR" || echo "‚ö†Ô∏è No data folder found!"
      
          # Safety: ensure JSON files exist and are readable
          for f in "$DATA_DIR"/*.json; do
            if [ ! -s "$f" ]; then
              echo "‚ö†Ô∏è Missing or empty file: $f"
            else
              echo "‚úÖ Found $f ($(wc -l < "$f") lines)"
            fi
          done
      
          echo "üß© Combining JSON metadata..."
          jq -s 'def safe(r): if r.result.records then r.result.records else (r.records // []) end;
           { "objects": safe(.[0]), "fields": safe(.[1]), "relationships": safe(.[2]),
             "validation_rules": safe(.[3]), "triggers": safe(.[4]), "flows": safe(.[5]),
             "record_types": safe(.[6]) }' \
                "$DATA_DIR"/objects.json "$DATA_DIR"/fields.json "$DATA_DIR"/relationships.json \
                "$DATA_DIR"/validation_rules.json "$DATA_DIR"/triggers.json "$DATA_DIR"/flows.json \
                "$DATA_DIR"/record_types.json > "$DATA_DIR/full_metadata.json"
          
          record_count=$(jq '[.objects, .fields, .relationships, .validation_rules, .triggers, .flows, .record_types] | map(length) | add' "$DATA_DIR/full_metadata.json")
          if [ "$record_count" -eq 0 ]; then
            echo "‚ùå No metadata found in full_metadata"
            jq . "$DATA_DIR/full_metadata.json" | head -n 40
            exit 1
          fi
          echo "‚úÖ Metadata contains $record_count records"
      
          echo "üß† Sending prompt to Ollama..."
          SYSTEM_PROMPT='You are a senior Salesforce Data Architect. Be concise and factual. Base every point ONLY on the JSON.'
          USER_PROMPT=$(cat << 'EOF'
          You are a Salesforce Data Architect. Analyze the provided Salesforce metadata JSON and focus specifically on:

          ## üîç Missing Indexes
          - Identify fields that are frequently used in relationships or likely queried but lack IsIndexed=true.
          - Highlight numeric or text fields that may benefit from indexing for performance.

          ## üß© Duplicate Fields
          - Detect fields with the same Label, QualifiedApiName, or similar purposes across different objects.
          - Note potential redundancies that could cause confusion or maintenance issues.

          ## üîó Relationships
          - Describe key Lookup and Master-Detail relationships.
          - Identify circular or weakly defined relationships.

          ## ‚úÖ Recommendations
          - Provide short, factual bullet-point advice based on the above findings.

          Use bullet points only, no paragraphs. If any section lacks data, write "Insufficient data".

          ### METADATA INPUT ###
          EOF
          )
          echo "$USER_PROMPT" > prompt.txt
          jq -c '.' "$DATA_DIR/full_metadata.json" >> prompt.txt
      
          # Create JSON payload file to avoid command-line length limits
          cat > request.json << EOF
          {
            "model": "$MODEL",
            "prompt": $(jq -Rs . < prompt.txt),
            "system": "$SYSTEM_PROMPT",
            "options": {"temperature": 0.2, "top_p": 0.9},
            "stream": false
          }
          EOF
      
          ollama_response=$(curl -s http://localhost:11434/api/generate \
            -H "Content-Type: application/json" \
            -d @request.json | jq -r '.response // empty')
      
          if [ -z "$ollama_response" ]; then
            echo "‚ùå Ollama returned empty response"
            exit 1
          fi
      
          echo "# Salesforce Data Model Analysis Report" > "$REPORT_FILE"
          echo "**Model:** $MODEL" >> "$REPORT_FILE"
          echo "**Generated:** $(date)" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "$ollama_response" >> "$REPORT_FILE"
          echo "‚úÖ AI analysis completed successfully"
          rm -f request.json prompt.txt
          
      - uses: actions/upload-artifact@v4
        with:
          name: ai-data-model-report
          path: data_model_analysis_*.md
          retention-days: 14

      - name: üìÑ AI Summary
        run: |
          echo "## üß† AI Data Model Summary" >> $GITHUB_STEP_SUMMARY
          echo "- Model: \`${{ github.event.inputs.model_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Generated report successfully" >> $GITHUB_STEP_SUMMARY
