name: AI-Powered New Data Model Analyzer (Lite-Safe)

on:
  workflow_dispatch:
    inputs:
      org_alias:
        description: "Salesforce org alias"
        required: true
        default: "dev"
      model_name:
        description: "Ollama model to use"
        required: true
        default: "llama3:latest"

env:
  NODE_VERSION: "20"
  DATA_DIR: "data-model-data"

jobs:
  collect-data:
    name: Collect Salesforce Metadata
    runs-on: ubuntu-latest
    outputs:
      has_data: ${{ steps.check.outputs.has_data }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node + Salesforce CLI
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Salesforce CLI + jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq
          npm install -g @salesforce/cli

      - name: Authenticate to Salesforce
        run: |
          echo "${{ secrets.ORG_SFDX_URL }}" | sf org login sfdx-url \
            --alias "${{ github.event.inputs.org_alias }}" \
            --sfdx-url-stdin

      - name: Query Salesforce Metadata (Safe Mode)
        run: |
          mkdir -p "$DATA_DIR"
          queries=(
            "objects:SELECT DeveloperName,Label,NamespacePrefix,ExternalSharingModel,InternalSharingModel FROM EntityDefinition WHERE IsCustomizable=true LIMIT 2000"
            "fields:SELECT QualifiedApiName,EntityDefinition.DeveloperName,DataType,IsIndexed,IsCalculated,IsNillable,Length,Precision,Scale FROM FieldDefinition WHERE EntityDefinition.IsCustomizable=true LIMIT 2000"
            "relationships:SELECT QualifiedApiName,EntityDefinition.DeveloperName,RelationshipName,ReferenceTo FROM FieldDefinition WHERE EntityDefinition.IsCustomizable=true AND DataType IN ('Lookup','MasterDetail') LIMIT 2000"
            "validation_rules:SELECT ValidationName,EntityDefinition.DeveloperName,Active,ErrorMessage,Description FROM ValidationRule WHERE Active=true LIMIT 2000"
            "triggers:SELECT Name,TableEnumOrId,Status,CreatedDate,LastModifiedDate FROM ApexTrigger LIMIT 2000"
            "flows:SELECT DeveloperName,Description,Status,ProcessType,CreatedDate,LastModifiedDate FROM FlowDefinition LIMIT 2000"
            "record_types:SELECT DeveloperName,SobjectType,Name,Description,IsActive FROM RecordType LIMIT 2000"
          )
          for q in "${queries[@]}"; do
            name=${q%%:*}
            soql=${q#*:}
            echo "🔍 Querying $name..."
            sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
              --result-format json --query "$soql" > "$DATA_DIR/${name}.json" || echo '{"result":{"records":[]}}' > "$DATA_DIR/${name}.json"
          done

      - name: Validate Data Availability
        id: check
        run: |
          object_count=$(jq -r '.result.totalSize // 0' "$DATA_DIR/objects.json")
          field_count=$(jq -r '.result.totalSize // 0' "$DATA_DIR/fields.json")
          echo "Objects: $object_count, Fields: $field_count"
          if [ "$object_count" -gt 0 ] && [ "$field_count" -gt 0 ]; then
            echo "✅ Data model metadata available"
            echo "has_data=true" >> $GITHUB_OUTPUT
          else
            echo "⚠️ No metadata found"
            echo "has_data=false" >> $GITHUB_OUTPUT
          fi

      - uses: actions/upload-artifact@v4
        with:
          name: data-model-metadata-lite
          path: ${{ env.DATA_DIR }}
          retention-days: 7

  analyze-ai:
    name: Analyze Data Model (AI)
    runs-on: ubuntu-latest
    needs: collect-data
    if: needs.collect-data.outputs.has_data == 'true'
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: data-model-metadata-lite
          path: data

      - name: Setup Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve &
          for i in {1..20}; do
            if curl -s http://localhost:11434/api/version >/dev/null; then
              echo "✅ Ollama API ready"
              break
            fi
            echo "⏳ Waiting for Ollama to start ($i/20)..."
            sleep 3
          done
          ollama pull "${{ github.event.inputs.model_name }}"

      - name: 🧠 Analyze Data Model with AI
        id: analyze_model
        shell: bash
        run: |
          echo "🔍 Checking extracted metadata..."
          if [ ! -d "data/full_metadata" ]; then
            echo "❌ No metadata found in data/full_metadata"
            exit 1
          fi
      
          FILE_COUNT=$(find data/full_metadata -type f -name "*.json" | wc -l)
          echo "📁 Found $FILE_COUNT metadata JSON files."
      
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "❌ No JSON metadata files detected!"
            exit 1
          fi
      
          echo "🧩 Merging Salesforce metadata JSON files safely..."
          MERGED_FILE="merged_data_model.json"
      
          # Use find + xargs + jq to safely merge all JSON files
          find data/full_metadata -type f -name "*.json" -print0 | \
          xargs -0 jq -s '
            reduce .[] as $item ({"objects":[]};
              .objects += ($item.result.records // $item.records // [])
            )
          ' > "$MERGED_FILE"
      
          echo "✅ JSON files merged successfully into $MERGED_FILE"
      
          # Check file size sanity
          FILE_SIZE=$(stat -c%s "$MERGED_FILE")
          echo "📦 Merged file size: $FILE_SIZE bytes"
      
          if [ "$FILE_SIZE" -lt 100 ]; then
            echo "⚠️ Merged file appears empty or too small. Aborting analysis."
            exit 1
          fi
      
          # Now analyze with Ollama or your AI model
          REPORT_FILE="data_model_analysis_$(date +%Y%m%d_%H%M%S).md"
          echo "🧠 Sending merged model to AI for analysis..."
          
          ollama run llama3:latest --system "You are a senior Salesforce Data Architect. Analyze the provided JSON data model and generate an insightful structured report." \
            --file "$MERGED_FILE" > "$REPORT_FILE"
      
          echo "✅ AI analysis complete. Report saved to $REPORT_FILE"
      
          echo "📝 Report Summary:"
          head -n 20 "$REPORT_FILE"
      
          echo "SUMMARY_FILE=data_model_summary.txt" >> $GITHUB_ENV
          echo "**Summary:** $(grep -m1 -A3 'Recommendations' "$REPORT_FILE" | tr '\n' ' ')" >> "$GITHUB_STEP_SUMMARY"

      - uses: actions/upload-artifact@v4
        with:
          name: ai-data-model-report
          path: data_model_analysis_*.md
          retention-days: 14

      - name: 📄 AI Summary
        run: |
          echo "## 🧠 AI Data Model Summary" >> $GITHUB_STEP_SUMMARY
          echo "- Model: \`${{ github.event.inputs.model_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Generated report successfully" >> $GITHUB_STEP_SUMMARY
