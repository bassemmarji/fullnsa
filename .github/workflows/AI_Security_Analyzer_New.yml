name: AI-Powered New Data Model Analyzer (Lite-Safe)

on:
  workflow_dispatch:
    inputs:
      org_alias:
        description: "Salesforce org alias"
        required: true
        default: "dev"
      model_name:
        description: "Ollama model to use"
        required: true
        default: "llama3:latest"

env:
  NODE_VERSION: "20"
  DATA_DIR: "data-model-data"

jobs:
  collect-data:
    name: Collect Salesforce Metadata
    runs-on: ubuntu-latest
    outputs:
      has_data: ${{ steps.check.outputs.has_data }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node + Salesforce CLI
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Salesforce CLI + jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq
          npm install -g @salesforce/cli
      - name: Authenticate to Salesforce
        run: |
          echo "${{ secrets.ORG_SFDX_URL }}" | sf org login sfdx-url \
            --alias "${{ github.event.inputs.org_alias }}" \
            --sfdx-url-stdin
      - name: Query Salesforce Metadata (Safe Mode)
        run: |
          mkdir -p "$DATA_DIR"
          echo "ðŸ” Querying EntityDefinition..."
          sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT DeveloperName, Label, NamespacePrefix, ExternalSharingModel, InternalSharingModel 
                     FROM EntityDefinition 
                     WHERE IsCustomizable = true 
                     LIMIT 2000" > "$DATA_DIR/objects.json" || echo '{"result":{"records":[]}}' > "$DATA_DIR/objects.json"
          echo "ðŸ” Querying FieldDefinition..."
          sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT QualifiedApiName, EntityDefinition.DeveloperName, DataType, IsIndexed, IsCalculated, IsNillable, Length, Precision, Scale 
                     FROM FieldDefinition 
                     WHERE EntityDefinition.IsCustomizable = true 
                     LIMIT 2000" > "$DATA_DIR/fields.json" || echo '{"result":{"records":[]}}' > "$DATA_DIR/fields.json"
          echo "ðŸ” Querying Relationships..."
          sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT QualifiedApiName, EntityDefinition.DeveloperName, RelationshipName, ReferenceTo 
                     FROM FieldDefinition 
                     WHERE DataType IN ('Lookup','MasterDetail') 
                     LIMIT 2000" > "$DATA_DIR/relationships.json" || echo '{"result":{"records":[]}}' > "$DATA_DIR/relationships.json"
          echo "ðŸ” Querying Validation Rules..."
          sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT ValidationName, EntityDefinition.DeveloperName, Active, ErrorMessage, Description 
                     FROM ValidationRule 
                     WHERE Active = true 
                     LIMIT 2000" > "$DATA_DIR/validation_rules.json" || echo '{"result":{"records":[]}}' > "$DATA_DIR/validation_rules.json"
          echo "ðŸ¤– Querying Apex Triggers..."
          sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT Name, TableEnumOrId, Status, CreatedDate, LastModifiedDate 
                     FROM ApexTrigger 
                     LIMIT 2000" > "$DATA_DIR/triggers.json" || echo '{"result":{"records":[]}}' > "$DATA_DIR/triggers.json"
          echo "âš™ï¸ Querying Flow Definitions..."
          sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT DeveloperName, Description, Status, ProcessType, CreatedDate, LastModifiedDate 
                     FROM FlowDefinition 
                     LIMIT 2000" > "$DATA_DIR/flows.json" || echo '{"result":{"records":[]}}' > "$DATA_DIR/flows.json"
          echo "ðŸ“‹ Querying Record Types..."
          sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT DeveloperName, SobjectType, Name, Description, IsActive 
                     FROM RecordType 
                     LIMIT 2000" > "$DATA_DIR/record_types.json" || echo '{"result":{"records":[]}}' > "$DATA_DIR/record_types.json"
      - name: Validate Data Availability
        id: check
        run: |
          object_count=$(jq -r '.result.totalSize // 0' "$DATA_DIR/objects.json")
          field_count=$(jq -r '.result.totalSize // 0' "$DATA_DIR/fields.json")
          echo "Objects: $object_count, Fields: $field_count"
          if [ "$object_count" -gt 0 ] && [ "$field_count" -gt 0 ]; then
            echo "âœ… Data model metadata available"
            echo "has_data=true" >> $GITHUB_OUTPUT
          else
            echo "âš ï¸ No metadata found"
            echo "has_data=false" >> $GITHUB_OUTPUT
          fi
      - uses: actions/upload-artifact@v4
        with:
          name: data-model-metadata-lite
          path: ${{ env.DATA_DIR }}
          retention-days: 7

  analyze-ai:
    name: Analyze Data Model (AI)
    runs-on: ubuntu-latest
    needs: collect-data
    if: needs.collect-data.outputs.has_data == 'true'
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: data-model-metadata-lite
          path: data

      - name: Setup Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve &
          for i in {1..20}; do
            curl -s http://localhost:11434/api/version && break
            sleep 2
          done
          ollama pull "${{ github.event.inputs.model_name }}"
      - name: Analyze Data Model with AI
        run: |
          REPORT_FILE="data_model_analysis.md"
          MODEL="${{ github.event.inputs.model_name }}"
          echo "# Salesforce Data Model Analysis Report" > "$REPORT_FILE"
          echo "**Model:** $MODEL" >> "$REPORT_FILE"
          echo "**Generated:** $(date)" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          prompt="You are a senior Salesforce Data Architect.
          Analyze the provided metadata (objects, fields, relationships, etc).
          Focus on normalization, relationships, indexing, performance, etc."
          
          # Combine all JSON into a single input file (optional)
          jq -s '{objects: .[0], fields: .[1], relationships: .[2]}' \
              data/objects.json data/fields.json data/relationships.json > data/combined.json
          
          # Run Ollama with a prompt and feed JSON via stdin
          ollama run "$MODEL" "$prompt" < data/combined.json >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "---" >> "$REPORT_FILE"
          echo "## Technical Summary" >> "$REPORT_FILE"
          echo "- Objects: $(jq -r '.result.totalSize // 0' data/objects.json)" >> "$REPORT_FILE"
          echo "- Fields: $(jq -r '.result.totalSize // 0' data/fields.json)" >> "$REPORT_FILE"
          echo "- Generated: $(date)" >> "$REPORT_FILE"
          
      - uses: actions/upload-artifact@v4
        with:
          name: ai-data-model-report
          path: data_model_analysis.md
          retention-days: 14

      - name: ðŸ“„ AI Summary
        run: |
          echo "## ðŸ§  AI Data Model Summary" >> $GITHUB_STEP_SUMMARY
          echo "- Model: \`${{ github.event.inputs.model_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Report: \`data_model_analysis.md\`" >> $GITHUB_STEP_SUMMARY
          echo "- Artifact: \`ai-data-model-report\`" >> $GITHUB_STEP_SUMMARY
