name: AI-Powered New Data Model Analyzer (Lite-Safe)

on:
  workflow_dispatch:
    inputs:
      org_alias:
        description: "Salesforce org alias"
        required: true
        default: "Full-NSA"
      model_name:
        description: "Ollama model to use"
        required: true
        default: "llama3:latest"

env:
  NODE_VERSION: "20"
  DATA_DIR: "data"  # Simplified for consistency

jobs:
  collect-data:
    name: Collect Salesforce Metadata
    runs-on: ubuntu-latest
    outputs:
      has_data: ${{ steps.check.outputs.has_data }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node + Salesforce CLI
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Salesforce CLI + jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq
          npm install -g @salesforce/cli

      - name: Authenticate to Salesforce
        run: |
          echo "${{ secrets.ORG_SFDX_URL }}" | sf org login sfdx-url \
            --alias "${{ github.event.inputs.org_alias }}" \
            --sfdx-url-stdin

      - name: Test Tooling API Access
        run: |
          echo "üîç Testing post-auth Tooling access..."
          sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
            --query "SELECT count() FROM EntityDefinition LIMIT 1" \
            --result-format human || echo "‚ùå Quick test failed - check permissions"
          echo "üìä Full EntityDefinition count (for reference):"
          sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
            --query "SELECT count() FROM EntityDefinition" \
            --result-format human || echo "‚ùå Full count test failed"

      - name: Query Salesforce Metadata (Safe Mode)
        run: |
          mkdir -p "$DATA_DIR"

          echo "üîç Querying core Salesforce metadata (safe mode)..."

          queries=(
            "objects:SELECT Id,DeveloperName,Label,NamespacePrefix,ExternalSharingModel,InternalSharingModel FROM EntityDefinition LIMIT 2000"
            "fields:SELECT QualifiedApiName,EntityDefinition.DeveloperName,DataType,IsIndexed,IsCalculated,IsNillable,Length,Precision,Scale FROM FieldDefinition WHERE EntityDefinition.DeveloperName != null LIMIT 2000"
            "validation_rules:SELECT ValidationName,EntityDefinition.DeveloperName,Active,ErrorMessage,Description FROM ValidationRule WHERE Active=true LIMIT 2000"
            "triggers:SELECT Name,TableEnumOrId,Status,CreatedDate,LastModifiedDate FROM ApexTrigger LIMIT 2000"
            "flows:SELECT MasterLabel, Definition.DeveloperName, Description, Status, ProcessType, CreatedDate, LastModifiedDate FROM Flow WHERE Status = 'Active' LIMIT 2000"
            "record_types:SELECT Name, SobjectType, Description, IsActive FROM RecordType LIMIT 2000"
          )
      
          for q in "${queries[@]}"; do
            name="${q%%:*}"
            soql="${q#*:}"
            echo "üîç Querying $name..."
            
            if sf data query \
                --use-tooling-api \
                --target-org "${{ github.event.inputs.org_alias }}" \
                --result-format json \
                --query "$soql" > "$DATA_DIR/${name}.json" 2>/tmp/sf_err_${name}.log; then
              echo "‚úÖ $name: success"
              records_len=$(jq -r '.result.records // .records // [] | length' "$DATA_DIR/${name}.json")
              total_size=$(jq -r '.result.totalSize // .totalSize // empty' "$DATA_DIR/${name}.json")
              echo "üìä $name records length: $records_len (totalSize: $total_size)"
            else
              echo "‚ö†Ô∏è  $name: failed ‚Äì $(cat /tmp/sf_err_${name}.log)"
              echo '{"totalSize":0,"done":true,"records":[]}' > "$DATA_DIR/${name}.json"
              echo "üìä $name records length: 0 (fallback)"
            fi
            rm -f /tmp/sf_err_${name}.log
          done
      
          # === STEP 2: Query relationship fields (requires EntityDefinitionId) ===
          echo "üîç Querying relationships (per object)..."
          relationships_file="$DATA_DIR/relationships.json"
          tmp_dir="$(mktemp -d)"
      
          object_record_count=$(jq -r '.result.records // .records // [] | length' "$DATA_DIR/objects.json")
          if [ ! -s "$DATA_DIR/objects.json" ] || [ "$object_record_count" -eq 0 ]; then
            echo '{"totalSize":0,"done":true,"records":[]}' > "$relationships_file"
            echo "‚úÖ relationships: no objects found (length: $object_record_count)"
          else
            rel_count=0
            object_ids=$(jq -r '.result.records // .records // [] | .[0:10] | .[] | select(.Id and .DeveloperName) | "\(.Id) \(.DeveloperName)"' "$DATA_DIR/objects.json")
            if [ -z "$object_ids" ]; then
              echo "‚ö†Ô∏è No sample objects for relationships loop"
            else
              echo "$object_ids" | while IFS= read -r line; do
                entity_id=$(echo "$line" | cut -d' ' -f1)
                developer_name=$(echo "$line" | cut -d' ' -f2-)
                echo "  ‚Üí $developer_name ($entity_id)"
      
                sf data query \
                  --use-tooling-api \
                  --target-org "${{ github.event.inputs.org_alias }}" \
                  --result-format json \
                  --query "SELECT QualifiedApiName, EntityDefinition.DeveloperName, RelationshipName, ReferenceTo FROM FieldDefinition WHERE EntityDefinitionId = '${entity_id}' AND (DataType LIKE 'Lookup(%' OR DataType LIKE 'MasterDetail(%') LIMIT 100" \
                  > "$tmp_dir/${entity_id}.json" 2>/dev/null || echo '{"totalSize":0,"done":true,"records":[]}' > "$tmp_dir/${entity_id}.json"
              done
            fi
      
            # Merge all relationship results
            if compgen -G "$tmp_dir/*.json" > /dev/null; then
              merged_records=$(jq -s '(map(.result.records // .records // []) | flatten | length)' "$tmp_dir"/*.json)
              echo '{"totalSize":'$merged_records',"done":true,"records":'$(jq -s 'map(.result.records // .records // []) | flatten' "$tmp_dir"/*.json | jq -c .)' }' > "$relationships_file"
              rel_count=$(jq -r '.totalSize // empty' "$relationships_file")
            else
              echo '{"totalSize":0,"done":true,"records":[]}' > "$relationships_file"
              rel_count=0
            fi
      
            rm -rf "$tmp_dir"
            echo "‚úÖ relationships: completed (records length: $rel_count)"
          fi
                    
      - name: Validate Data Availability
        id: check
        run: |
          object_count=$(jq -r '.result.totalSize // .totalSize // 0' "$DATA_DIR/objects.json")
          field_count=$(jq -r '.result.totalSize // .totalSize // 0' "$DATA_DIR/fields.json")
          object_len=$(jq -r '.result.records // .records // [] | length' "$DATA_DIR/objects.json")
          field_len=$(jq -r '.result.records // .records // [] | length' "$DATA_DIR/fields.json")
          echo "Objects: count=$object_count (len=$object_len), Fields: count=$field_count (len=$field_len)"
          if [ "$object_count" -gt 0 ] && [ "$field_count" -gt 0 ]; then
            echo "‚úÖ Data model metadata available"
            echo "has_data=true" >> $GITHUB_OUTPUT
          else
            echo "‚ö†Ô∏è No metadata found (check org/permissions)"
            echo "has_data=false" >> $GITHUB_OUTPUT
          fi

      - uses: actions/upload-artifact@v4
        if: always()  # Upload even on failure for debugging
        with:
          name: data-model-metadata-lite
          path: ${{ env.DATA_DIR }}
          retention-days: 7

  analyze-ai:
    name: Analyze Data Model (AI)
    runs-on: ubuntu-latest
    needs: collect-data
    if: needs.collect-data.outputs.has_data == 'true'
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: data-model-metadata-lite
          path: ${{ env.DATA_DIR }}

      - name: Setup Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve &
          for i in {1..20}; do
            if curl -s http://localhost:11434/api/version >/dev/null; then
              echo "‚úÖ Ollama API ready"
              break
            fi
            echo "‚è≥ Waiting for Ollama to start ($i/20)..."
            sleep 3
          done
          if [ $i -eq 20 ]; then
            echo "‚ùå Ollama failed to start"
            exit 1
          fi
          ollama pull "${{ github.event.inputs.model_name }}"

      - name: Analyze Data Model with AI
        run: |
          echo "üß† Starting AI Analysis Step..."
          REPORT_FILE="data_model_analysis_$(date +%Y%m%d_%H%M%S).md"
          MODEL="${{ github.event.inputs.model_name }}"
      
          echo "üîç Checking metadata files..."
          ls -lh "$DATA_DIR" || echo "‚ö†Ô∏è No data folder found!"
      
          # Safety: ensure JSON files exist and are readable
          for f in "$DATA_DIR"/*.json; do
            if [ ! -s "$f" ]; then
              echo "‚ö†Ô∏è Missing or empty file: $f"
            else
              echo "‚úÖ Found $f ($(wc -l < "$f") lines)"
            fi
          done
      
          echo "üß© Combining JSON metadata..."
          jq -s 'def safe(r): if r.result.records then r.result.records else (r.records // []) end;
           { "objects": safe(.[0]), "fields": safe(.[1]), "relationships": safe(.[2]),
             "validation_rules": safe(.[3]), "triggers": safe(.[4]), "flows": safe(.[5]),
             "record_types": safe(.[6]) }' \
                "$DATA_DIR"/objects.json "$DATA_DIR"/fields.json "$DATA_DIR"/relationships.json \
                "$DATA_DIR"/validation_rules.json "$DATA_DIR"/triggers.json "$DATA_DIR"/flows.json \
                "$DATA_DIR"/record_types.json > "$DATA_DIR/full_metadata.json"
          
          record_count=$(jq '[.objects, .fields, .relationships, .validation_rules, .triggers, .flows, .record_types] | map(length) | add' "$DATA_DIR/full_metadata.json")
          if [ "$record_count" -eq 0 ]; then
            echo "‚ùå No metadata found in full_metadata"
            jq . "$DATA_DIR/full_metadata.json" | head -n 40
            exit 1
          fi
          echo "‚úÖ Metadata contains $record_count records"
      
          echo "üß† Sending prompt to Ollama..."
          SYSTEM_PROMPT='You are a senior Salesforce Data Architect. Be concise and factual. Base every point ONLY on the JSON.'
          USER_PROMPT=$(cat << 'EOF'
          You are a Salesforce Data Architect. Analyze the provided Salesforce metadata JSON and focus specifically on:

          ## üîç Missing Indexes
          - Identify fields that are frequently used in relationships or likely queried but lack IsIndexed=true.
          - Highlight numeric or text fields that may benefit from indexing for performance.

          ## üß© Duplicate Fields
          - Detect fields with the same Label, QualifiedApiName, or similar purposes across different objects.
          - Note potential redundancies that could cause confusion or maintenance issues.

          ## üîó Relationships
          - Describe key Lookup and Master-Detail relationships.
          - Identify circular or weakly defined relationships.

          ## ‚úÖ Recommendations
          - Provide short, factual bullet-point advice based on the above findings.

          Use bullet points only, no paragraphs. If any section lacks data, write "Insufficient data".

          ### METADATA INPUT ###
          EOF
          )
          echo "$USER_PROMPT" > prompt.txt
          jq -c '.' "$DATA_DIR/full_metadata.json" >> prompt.txt
      
          # Create JSON payload file to avoid command-line length limits
          cat > request.json << EOF
          {
            "model": "$MODEL",
            "prompt": $(jq -Rs . < prompt.txt),
            "system": "$SYSTEM_PROMPT",
            "options": {"temperature": 0.2, "top_p": 0.9},
            "stream": false
          }
          EOF
      
          ollama_response=$(curl -s http://localhost:11434/api/generate \
            -H "Content-Type: application/json" \
            -d @request.json | jq -r '.response // empty')
      
          if [ -z "$ollama_response" ]; then
            echo "‚ùå Ollama returned empty response"
            exit 1
          fi
      
          echo "# Salesforce Data Model Analysis Report" > "$REPORT_FILE"
          echo "**Model:** $MODEL" >> "$REPORT_FILE"
          echo "**Generated:** $(date)" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "$ollama_response" >> "$REPORT_FILE"
          echo "‚úÖ AI analysis completed successfully"
          rm -f request.json prompt.txt
          
      - uses: actions/upload-artifact@v4
        with:
          name: ai-data-model-report
          path: data_model_analysis_*.md
          retention-days: 14

      - name: üìÑ AI Summary
        run: |
          echo "## üß† AI Data Model Summary" >> $GITHUB_STEP_SUMMARY
          echo "- Model: \`${{ github.event.inputs.model_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Generated report successfully" >> $GITHUB_STEP_SUMMARY
