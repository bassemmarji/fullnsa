name: AI-Powered New Data Model Analyzer (Lite-Safe)

on:
  workflow_dispatch:
    inputs:
      org_alias:
        description: "Salesforce org alias"
        required: true
        default: "dev"
      model_name:
        description: "Ollama model to use"
        required: true
        default: "llama3:latest"

env:
  NODE_VERSION: "20"
  DATA_DIR: "data"  # Simplified for consistency

jobs:
  collect-data:
    name: Collect Salesforce Metadata
    runs-on: ubuntu-latest
    outputs:
      has_data: ${{ steps.check.outputs.has_data }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node + Salesforce CLI
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Salesforce CLI + jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq
          npm install -g @salesforce/cli

      - name: Authenticate to Salesforce
        run: |
          echo "${{ secrets.ORG_SFDX_URL }}" | sf org login sfdx-url \
            --alias "${{ github.event.inputs.org_alias }}" \
            --sfdx-url-stdin

      - name: Query Salesforce Metadata (Safe Mode)
        run: |
          mkdir -p "$DATA_DIR"
          queries=(
            "objects:SELECT DeveloperName,Label,NamespacePrefix,ExternalSharingModel,InternalSharingModel FROM EntityDefinition WHERE IsCustomizable=true LIMIT 2000"
            "fields:SELECT QualifiedApiName,EntityDefinition.DeveloperName,DataType,IsIndexed,IsCalculated,IsNillable,Length,Precision,Scale FROM FieldDefinition WHERE EntityDefinition.IsCustomizable=true LIMIT 2000"
            "relationships:SELECT QualifiedApiName,EntityDefinition.DeveloperName,RelationshipName,ReferenceTo FROM FieldDefinition WHERE EntityDefinition.IsCustomizable=true AND DataType IN ('Lookup','MasterDetail') LIMIT 2000"
            "validation_rules:SELECT ValidationName,EntityDefinition.DeveloperName,Active,ErrorMessage,Description FROM ValidationRule WHERE Active=true LIMIT 2000"
            "triggers:SELECT Name,TableEnumOrId,Status,CreatedDate,LastModifiedDate FROM ApexTrigger LIMIT 2000"
            "flows:SELECT DeveloperName,Description,Status,ProcessType,CreatedDate,LastModifiedDate FROM FlowDefinition LIMIT 2000"
            "record_types:SELECT DeveloperName,SobjectType,Name,Description,IsActive FROM RecordType LIMIT 2000"
          )
          for q in "${queries[@]}"; do
            name=${q%%:*}
            soql=${q#*:}
            echo "üîç Querying $name..."
            sf data query --use-tooling-api --target-org "${{ github.event.inputs.org_alias }}" \
              --result-format json --query "$soql" > "$DATA_DIR/${name}.json" || echo '{"totalSize":0,"done":true,"records":[]}' > "$DATA_DIR/${name}.json"
          done

      - name: Validate Data Availability
        id: check
        run: |
          object_count=$(jq -r '.totalSize // 0' "$DATA_DIR/objects.json")
          field_count=$(jq -r '.totalSize // 0' "$DATA_DIR/fields.json")
          echo "Objects: $object_count, Fields: $field_count"
          if [ "$object_count" -gt 0 ] && [ "$field_count" -gt 0 ]; then
            echo "‚úÖ Data model metadata available"
            echo "has_data=true" >> $GITHUB_OUTPUT
          else
            echo "‚ö†Ô∏è No metadata found (check if org has custom objects/fields)"
            echo "has_data=false" >> $GITHUB_OUTPUT
          fi

      - uses: actions/upload-artifact@v4
        if: always()  # Upload even on failure for debugging
        with:
          name: data-model-metadata-lite
          path: ${{ env.DATA_DIR }}
          retention-days: 7

  analyze-ai:
    name: Analyze Data Model (AI)
    runs-on: ubuntu-latest
    needs: collect-data
    if: needs.collect-data.outputs.has_data == 'true'
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: data-model-metadata-lite
          path: ${{ env.DATA_DIR }}

      - name: Setup Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve &
          for i in {1..20}; do
            if curl -s http://localhost:11434/api/version >/dev/null; then
              echo "‚úÖ Ollama API ready"
              break
            fi
            echo "‚è≥ Waiting for Ollama to start ($i/20)..."
            sleep 3
          done
          if [ $i -eq 20 ]; then
            echo "‚ùå Ollama failed to start"
            exit 1
          fi
          ollama pull "${{ github.event.inputs.model_name }}"

      - name: Analyze Data Model with AI
        run: |
          echo "üß† Starting AI Analysis Step..."
          REPORT_FILE="data_model_analysis_$(date +%Y%m%d_%H%M%S).md"
          MODEL="${{ github.event.inputs.model_name }}"
      
          echo "üîç Checking metadata files..."
          ls -lh "$DATA_DIR" || echo "‚ö†Ô∏è No data folder found!"
      
          # Safety: ensure JSON files exist and are readable
          for f in "$DATA_DIR"/*.json; do
            if [ ! -s "$f" ]; then
              echo "‚ö†Ô∏è Missing or empty file: $f"
            else
              echo "‚úÖ Found $f ($(wc -l < "$f") lines)"
            fi
          done
      
          echo "üß© Combining JSON metadata..."
          jq -s 'def safe(r): if r.result.records then r.result.records else (r.records // []) end;
           { "objects": safe(.[0]), "fields": safe(.[1]), "relationships": safe(.[2]),
             "validation_rules": safe(.[3]), "triggers": safe(.[4]), "flows": safe(.[5]),
             "record_types": safe(.[6]) }' \
                "$DATA_DIR"/objects.json "$DATA_DIR"/fields.json "$DATA_DIR"/relationships.json \
                "$DATA_DIR"/validation_rules.json "$DATA_DIR"/triggers.json "$DATA_DIR"/flows.json \
                "$DATA_DIR"/record_types.json > "$DATA_DIR/full_metadata.json"
          
          record_count=$(jq '[.objects, .fields, .relationships, .validation_rules, .triggers, .flows, .record_types] | map(length) | add' "$DATA_DIR/full_metadata.json")
          if [ "$record_count" -eq 0 ]; then
            echo "‚ùå No metadata found in full_metadata"
            jq . "$DATA_DIR/full_metadata.json" | head -n 40
            exit 1
          fi
          echo "‚úÖ Metadata contains $record_count records"
      
          echo "üß† Sending prompt to Ollama..."
          SYSTEM_PROMPT='You are a senior Salesforce Data Architect. Be concise and factual. Base every point ONLY on the JSON.'
          USER_PROMPT=$(cat << 'EOF'
          Analyze the provided Salesforce metadata JSON and produce exactly these sections:

          ## üîç Key Findings
          ## üèõ Object Modeling & Relationships
          ## üöÄ Performance & Indexing
          ## üîê Security & Governance
          ## ‚úÖ Recommendations

          Use bullet points only, no paragraphs. If data is sparse, write "Insufficient data".
          ### METADATA INPUT ###
          EOF
          )
          echo "$USER_PROMPT" > prompt.txt
          jq -c '.' "$DATA_DIR/full_metadata.json" >> prompt.txt
      
          echo "# Salesforce Data Model Analysis Report" > "$REPORT_FILE"
          echo "**Model:** $MODEL" >> "$REPORT_FILE"
          echo "**Generated:** $(date)" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
      
          ollama_response=$(curl -s http://localhost:11434/api/generate \
            -H "Content-Type: application/json" \
            -d "{
              \"model\": \"$MODEL\",
              \"prompt\": \"$(jq -Rs . < prompt.txt)\",
              \"system\": \"$SYSTEM_PROMPT\",
              \"options\": {\"temperature\": 0.2, \"top_p\": 0.9},
              \"stream\": false
            }" | jq -r '.response // empty')
      
          if [ -z "$ollama_response" ]; then
            echo "‚ùå Ollama returned empty response"
            exit 1
          fi
      
          echo "$ollama_response" >> "$REPORT_FILE"
          echo "‚úÖ AI analysis completed successfully"
    
      - uses: actions/upload-artifact@v4
        with:
          name: ai-data-model-report
          path: data_model_analysis_*.md
          retention-days: 14

      - name: üìÑ AI Summary
        run: |
          echo "## üß† AI Data Model Summary" >> $GITHUB_STEP_SUMMARY
          echo "- Model: \`${{ github.event.inputs.model_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Generated report successfully" >> $GITHUB_STEP_SUMMARY
