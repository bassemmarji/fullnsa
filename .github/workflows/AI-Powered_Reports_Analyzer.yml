name: AI-Powered Reports Analyzer (Enhanced)

on:
  workflow_dispatch:
    inputs:
      org_alias:
        description: "Salesforce org alias"
        required: true
        default: "dev"
      model_name:
        description: "Ollama model"
        required: true
        default: "llama3:latest"

env:
  NODE_VERSION: "20"
  DATA_DIR: "data"

jobs:
  collect-and-analyze-reports:
    name: Collect + Analyze Reports (Hardis + Metadata)
    runs-on: ubuntu-latest
    outputs:
      has_data: ${{ steps.check.outputs.has_data }}

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install common linux packages
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq curl unzip

      - name: Install Salesforce CLI
        uses: sfdx-actions/setup-sfdx@v1
        with:
          version: latest

      - name: Install sfdx-hardis (global)
        run: |
          # ensure npm is available from setup-node
          npm install -g sfdx-hardis
          sfdx-hardis --version || true

      - name: Authenticate to Salesforce
        run: |
          echo "${{ secrets.ORG_SFDX_URL }}" | sf org login sfdx-url \
            --alias "${{ github.event.inputs.org_alias }}" \
            --sfdx-url-stdin

      - name: Create data directory
        run: mkdir -p "$DATA_DIR"

      # -----------------------------------------------------------
      # METADATA COLLECTION (no ReportEvent)
      # -----------------------------------------------------------

      - name: Query Reports Metadata
        run: |
          sf data query \
            --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT Id, DeveloperName, Name, NamespacePrefix, Description, Format, FolderName, LastRunDate, LastViewedDate, LastReferencedDate FROM Report LIMIT 5000" \
            > "$DATA_DIR/reports.json"

      - name: Query Dashboard Usage (DashboardComponent)
        run: |
          sf data query \
            --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT Id, DashboardId, CustomReportId FROM DashboardComponent LIMIT 5000" \
            > "$DATA_DIR/dashboard_components.json"

      # -----------------------------------------------------------
      # HARDIS ANALYSIS (uses sfdx-hardis cli)
      # -----------------------------------------------------------

      - name: Run sfdx-hardis Report Analysis
        run: |
          # ensure data dir exists
          mkdir -p "$DATA_DIR"
          sfdx-hardis org:report:analyze \
            --target-org "${{ github.event.inputs.org_alias }}" \
            --outputfile "$DATA_DIR/hardis_report.json" \
            --json || echo "{}" > "$DATA_DIR/hardis_report.json"

      # -----------------------------------------------------------
      # CHECK FOR DATA
      # -----------------------------------------------------------

      - name: Check if reports exist
        id: check
        run: |
          # safe parsing if file missing or empty
          if [ ! -f "$DATA_DIR/reports.json" ] || [ ! -s "$DATA_DIR/reports.json" ]; then
            echo "has_data=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          count=$(jq '.result.records | length // .records | length // 0' "$DATA_DIR/reports.json")
          if [ "$count" -gt 0 ]; then
            echo "has_data=true" >> $GITHUB_OUTPUT
          else
            echo "has_data=false" >> $GITHUB_OUTPUT
          fi

      - uses: actions/upload-artifact@v4
        with:
          name: raw-and-hardis-data
          path: ${{ env.DATA_DIR }}
          retention-days: 7

  analyze-with-ai:
    name: AI-Powered Insight Generation
    runs-on: ubuntu-latest
    needs: collect-and-analyze-reports
    if: needs.collect-and-analyze-reports.outputs.has_data == 'true'

    steps:
      - uses: actions/checkout@v4

      - uses: actions/download-artifact@v4
        with:
          name: raw-and-hardis-data
          path: ${{ env.DATA_DIR }}

      # -----------------------------------------------------------
      # OLLAMA SETUP
      # -----------------------------------------------------------

      - name: Setup Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve & disown
          for i in {1..20}; do
            if curl -s http://localhost:11434/api/version >/dev/null; then break; fi
            sleep 2
          done
          ollama pull "${{ github.event.inputs.model_name }}" || true

      # -----------------------------------------------------------
      # DATA PREPROCESSING (Recency + Dashboard Usage)
      # -----------------------------------------------------------

      - name: Preprocess Data
        run: |
          set -euo pipefail
          rec_reports() { jq '.result.records // .records // []' "$1"; }
          rec_dash() { jq '.result.records // .records // []' "$1"; }

          # 1. DASHBOARD USAGE MAP (sort before group_by)
          rec_dash "$DATA_DIR/dashboard_components.json" | jq '
            sort_by(.CustomReportId) |
            group_by(.CustomReportId) |
            map({reportId: .[0].CustomReportId, dashboardCount: length})
          ' > "$DATA_DIR/dashboard_usage.json"

          # 2. ENRICH REPORTS WITH DASHBOARD USAGE + RECENCY SCORE
          # Recency Score: 3 = active (LastRunDate), 2 = viewed, 1 = referenced, 0 = stale
          jq -s '
            (.[0].result.records // .[0].records // []) as $reports |
            (.[1] // []) as $dash |
            $reports | map(
              . as $r |
              ($dash | map(select(.reportId == $r.Id)) | .[0].dashboardCount // 0) as $dashCount |
              (if ($r.LastRunDate // null) != null then 3
               elif ($r.LastViewedDate // null) != null then 2
               elif ($r.LastReferencedDate // null) != null then 1
               else 0 end) as $recency |
              $r + {
                dashboardUsage: $dashCount,
                recencyScore: $recency
              }
            )
          ' "$DATA_DIR/reports.json" "$DATA_DIR/dashboard_usage.json" \
            > "$DATA_DIR/reports_enriched.json"

          # INVALID REPORTS: no description and no view/reference activity
          jq '
            map(select(
              ((.Description // "") == "") and
              (.LastViewedDate == null and .LastReferencedDate == null)
            ))
          ' "$DATA_DIR/reports_enriched.json" > "$DATA_DIR/invalid_reports.json"

          # TOP 20 STALE REPORTS (lowest recencyScore, then dashboardUsage)
          jq 'sort_by(.recencyScore, .dashboardUsage) | .[0:20]' "$DATA_DIR/reports_enriched.json" > "$DATA_DIR/stale_reports.json"

          # TOP 20 ACTIVE REPORTS (highest recencyScore, then dashboardUsage)
          jq 'sort_by(.recencyScore, .dashboardUsage) | reverse | .[0:20]' "$DATA_DIR/reports_enriched.json" > "$DATA_DIR/top_reports.json"

          # FORMAT CATEGORIES (safe sort/group)
          jq 'sort_by(.Format) | group_by(.Format) | map({format: .[0].Format, count: length})' "$DATA_DIR/reports_enriched.json" > "$DATA_DIR/reports_by_category.json"

          # HARDIS FINDINGS (safe fallback)
          if [ -f "$DATA_DIR/hardis_report.json" ] && [ -s "$DATA_DIR/hardis_report.json" ]; then
            jq '.result.findings // .findings // []' "$DATA_DIR/hardis_report.json" > "$DATA_DIR/hardis_findings.json"
          else
            echo "[]" > "$DATA_DIR/hardis_findings.json"
          fi

      # -----------------------------------------------------------
      # AI ANALYSIS
      # -----------------------------------------------------------

      - name: AI Analysis
        env:
          MODEL: ${{ github.event.inputs.model_name }}
        run: |
          REPORT="salesforce_reports_analysis_$(date +%Y%m%d_%H%M%S).md"

          CONTEXT=$(jq -nc '{
            enriched: $enriched[0],
            stale: $stale[0],
            top: $top[0],
            categories: $categories[0],
            invalid: $invalid[0],
            hardis: $hardis[0]
          }' \
            --slurpfile enriched "$DATA_DIR/reports_enriched.json" \
            --slurpfile stale "$DATA_DIR/stale_reports.json" \
            --slurpfile top "$DATA_DIR/top_reports.json" \
            --slurpfile categories "$DATA_DIR/reports_by_category.json" \
            --slurpfile invalid "$DATA_DIR/invalid_reports.json" \
            --slurpfile hardis "$DATA_DIR/hardis_findings.json")

          PROMPT=$(cat << 'EOF'
          You are a Senior Salesforce Governance Analyst.
          
          Analyze the following dataset based on:
          - enriched report metadata (recencyScore, dashboardUsage, description quality)
          - stale vs active reports
          - invalid reports
          - reports by format
          - sfdx-hardis findings (security risks, technical debt)
          
          Produce a high-quality Markdown report with:
          1. Executive Summary
          2. Invalid or High-Risk Reports
          3. Stale Reports (Top 20)
          4. Most Active Reports (Top 20)
          5. Reports by Format
          6. sfdx-hardis Findings Summary
          7. Actionable Recommendations
          EOF
          )

          # send to Ollama (local) and extract response
          PAYLOAD=$(jq -n --arg model "$MODEL" --arg prompt "$PROMPT\n\nCONTEXT:\n$CONTEXT" '{model: $model, prompt: $prompt, stream: false}')
          RESPONSE=$(curl -s http://localhost:11434/api/generate \
            -H "Content-Type: application/json" \
            -d "$PAYLOAD" | jq -r '.response // "AI analysis failed."')

          {
            echo "# Salesforce Reports Governance Report"
            echo "**Generated:** $(date -u)"
            echo ""
            echo "$RESPONSE"
          } > "$REPORT"

      - uses: actions/upload-artifact@v4
        with:
          name: salesforce-reports-analysis
          path: salesforce_reports_analysis_*.md
          retention-days: 14
