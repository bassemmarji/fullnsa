name: AI-Powered Reports Analyzer (with sfdx-hardis)

on:
  workflow_dispatch:
    inputs:
      org_alias:
        description: "Salesforce org alias"
        required: true
        default: "dev"
      model_name:
        description: "Ollama model"
        required: true
        default: "llama3:latest"

env:
  NODE_VERSION: "20"
  DATA_DIR: "data"

jobs:
  collect-and-analyze-reports:
    name: Collect + Analyze Reports (Hardis + Metadata)
    runs-on: ubuntu-latest
    outputs:
      has_data: ${{ steps.check.outputs.has_data }}

    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install SF CLI & tools
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq curl
          npm install -g @salesforce/cli

      - name: Install sfdx-hardis plugin
        run: sf plugins install sfdx-hardis

      - name: Authenticate to Salesforce
        run: |
          echo "${{ secrets.ORG_SFDX_URL }}" | sf org login sfdx-url \
            --alias "${{ github.event.inputs.org_alias }}" \
            --sfdx-url-stdin

      - name: Create data directory
        run: mkdir -p "$DATA_DIR"

      # -----------------------------------------------------------
      #  STANDARD METADATA COLLECTION
      # -----------------------------------------------------------

      - name: Query Reports Metadata
        run: |
          sf data query \
            --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT Id, DeveloperName, Name, Format, Description, LastRunDate, LastViewedDate, LastReferencedDate FROM Report LIMIT 5000" \
            > "$DATA_DIR/reports.json"

      - name: Query Report Types
        run: |
          sf data query \
            --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query "SELECT Id, DeveloperName, BaseObject, JoinObjects, Category FROM ReportType" \
            > "$DATA_DIR/report_types.json"


      - name: Query Report Usage (ReportEvent)
        run: |
          sf data query --use-tooling-api \
            --target-org "${{ github.event.inputs.org_alias }}" \
            --result-format json \
            --query \"SELECT Id, ReportId, RunTime, Status, RowCount, CreatedDate FROM ReportEvent ORDER BY CreatedDate DESC LIMIT 5000\" \
            > "$DATA_DIR/report_usage.json"

      # -----------------------------------------------------------
      #  HARDIS ANALYSIS
      # -----------------------------------------------------------

      - name: Run sfdx-hardis Report Analysis
        run: |
          sf hardis:org:report:analyze \
            --target-org "${{ github.event.inputs.org_alias }}" \
            --outputfile "$DATA_DIR/hardis_report.json" \
            --json

      # -----------------------------------------------------------
      #  CHECK IF DATA EXISTS
      # -----------------------------------------------------------

      - name: Check if reports exist
        id: check
        run: |
          count=$(jq '.records | length // 0' "$DATA_DIR/reports.json")
          if [ "$count" -gt 0 ]; then
            echo "has_data=true" >> $GITHUB_OUTPUT
          else
            echo "has_data=false" >> $GITHUB_OUTPUT
          fi

      - uses: actions/upload-artifact@v4
        with:
          name: raw-and-hardis-data
          path: ${{ env.DATA_DIR }}
          retention-days: 7

  analyze-with-ai:
    name: AI-Powered Insight Generation
    runs-on: ubuntu-latest
    needs: collect-and-analyze-reports
    if: needs.collect-and-analyze-reports.outputs.has_data == 'true'

    steps:
      - uses: actions/checkout@v4

      - uses: actions/download-artifact@v4
        with:
          name: raw-and-hardis-data
          path: ${{ env.DATA_DIR }}

      # -----------------------------------------------------------
      #  OLLAMA SETUP
      # -----------------------------------------------------------

      - name: Setup Ollama
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama serve &
          for i in {1..20}; do
            if curl -s http://localhost:11434/api/version >/dev/null; then break; fi
            sleep 2
          done
          ollama pull "${{ github.event.inputs.model_name }}"

      # -----------------------------------------------------------
      #  DATA PREPROCESSING
      # -----------------------------------------------------------

      - name: Preprocess Data
        run: |
          rec() { jq '.records // .result.records // []' "$1"; }

          # INVALID REPORTS = missing description + missing run/view references
          rec "$DATA_DIR/reports.json" | jq '
            map(select(
              (.Description == null or .Description == "") and
              (.LastViewedDate == null and .LastReferencedDate == null)
            ))
          ' > "$DATA_DIR/invalid_reports.json"

          # USAGE SUMMARY
          rec "$DATA_DIR/report_usage.json" | jq '
            group_by(.ReportId) |
            map({ReportId: .[0].ReportId, runs: length})
          ' > "$DATA_DIR/report_usage_summary.json"

          # ENRICH REPORTS WITH USAGE
          jq -s '
            (.[0].records // []) as $reports |
            (.[1] // []) as $usage |
            $reports | map(. + {
              runs: ($usage | map(select(.ReportId == .Id)) | .[0].runs // 0)
            })
          ' "$DATA_DIR/reports.json" "$DATA_DIR/report_usage_summary.json" \
            > "$DATA_DIR/reports_enriched.json"

          # MOST/LEAST USED
          jq 'sort_by(.runs) | .[0:20]' "$DATA_DIR/reports_enriched.json" > "$DATA_DIR/least_used.json"
          jq 'sort_by(.runs) | reverse | .[0:20]' "$DATA_DIR/reports_enriched.json" > "$DATA_DIR/most_used.json"

          # CATEGORIES
          jq '
            group_by(.Format) |
            map({format: .[0].Format, count: length})
          ' "$DATA_DIR/reports_enriched.json" > "$DATA_DIR/reports_by_category.json"

          # EXTRACT HARDIS FINDINGS
          jq '.result.findings // []' "$DATA_DIR/hardis_report.json" > "$DATA_DIR/hardis_findings.json"

      # -----------------------------------------------------------
      #  AI ANALYSIS
      # -----------------------------------------------------------

      - name: AI Analysis with Hardis Context
        run: |
          MODEL="${{ github.event.inputs.model_name }}"
          REPORT="salesforce_reports_analysis_$(date +%Y%m%d_%H%M%S).md"

          CONTEXT=$(jq -c '{
            reports: (input | .reports_enriched),
            leastUsed: (input | .least_used),
            mostUsed: (input | .most_used),
            categories: (input | .categories),
            invalid: (input | .invalid_reports),
            hardis: (input | .hardis_findings)
          }' \
            --slurpfile reports_enriched "$DATA_DIR/reports_enriched.json" \
            --slurpfile least_used "$DATA_DIR/least_used.json" \
            --slurpfile most_used "$DATA_DIR/most_used.json" \
            --slurpfile categories "$DATA_DIR/reports_by_category.json" \
            --slurpfile invalid_reports "$DATA_DIR/invalid_reports.json" \
            --slurpfile hardis_findings "$DATA_DIR/hardis_findings.json")

          PROMPT=$(cat << 'EOF'
          You are a Senior Salesforce Governance Analyst.
          
          Analyze the following JSON dataset containing:
          - enriched report metadata
          - usage analytics
          - invalid reports
          - report categories
          - sfdx-hardis findings (security, technical debt, orphan reports)
          
          Produce a high-quality **Markdown report** with:
          
          ## Executive Summary
          - Total reports, invalid reports, usage overview
          - Security/performance concerns from Hardis
          
          ## Invalid or High-Risk Reports
          | Name | Issue | Hardis Risk Level |
          
          ## Rarely Used Reports (Top 20)
          | Name | Runs | Format |
          
          ## Most Used Reports (Top 20)
          | Name | Runs | Format |
          
          ## Reports by Format
          | Format | Count |
          
          ## sfdx-hardis Findings Summary
          - Critical or High issues
          - Recommended remediation
          
          End with **actionable recommendations** for governance, cleanup, and security.
          EOF
          )

          FINAL_PROMPT="$PROMPT

          CONTEXT (JSON):
          $CONTEXT
          "

          RESPONSE=$(curl -s http://localhost:11434/api/generate \
            -H "Content-Type: application/json" \
            -d "{\"model\":\"$MODEL\",\"prompt\":$(jq -R <<< "$FINAL_PROMPT"),\"stream\":false}" \
            | jq -r '.response // "AI analysis failed."')

          {
            echo "# Salesforce Reports Governance Report"
            echo "**Generated:** $(date -u)"
            echo ""
            echo "$RESPONSE"
          } > "$REPORT"

      - uses: actions/upload-artifact@v4
        with:
          name: salesforce-reports-analysis
          path: salesforce_reports_analysis_*.md
          retention-days: 14
